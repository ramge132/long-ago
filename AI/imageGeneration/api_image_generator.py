import os
import json
import base64
import asyncio
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from PIL import Image
import io
import requests
from openai import OpenAI
import google.generativeai as genai

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# ìºë¦­í„° íŒŒì¼ ê²½ë¡œ
CHARACTERS_DIR = os.path.join(os.path.dirname(__file__), "characters")

@dataclass
class Entity:
    name: str  # ì˜ì–´ ì´ë¦„ (ê³ ìœ  ì‹ë³„ì)
    korean_name: str
    entity_type: str  # 'ì¸ë¬¼', 'ì‚¬ë¬¼', 'ì¥ì†Œ'
    image_path: Optional[str] = None  # ìºë¦­í„°ë§Œ ê°€ì§
    prompt: Optional[str] = None      # ìºë¦­í„°ë§Œ ê°€ì§

class EntityManager:
    def __init__(self):
        self.entities: Dict[str, Entity] = {}
        self.korean_to_english_map: Dict[str, str] = {}
        self.load_entities()

    def load_entities(self):
        """init_db.sqlê³¼ ê¸°ì¡´ ìºë¦­í„° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë“  ê°œì²´ ë¡œë“œ"""
        
        # 1. ê¸°ì¡´ ìºë¦­í„° ì •ë³´ ë¡œë“œ (character í´ë” ê¸°ë°˜)
        character_details = {
            "alien": {"korean": "ì™¸ê³„ì¸"}, "beggar": {"korean": "ê°€ë‚œë±…ì´"}, "boy": {"korean": "ì†Œë…„"},
            "detective": {"korean": "íƒì •"}, "doctor": {"korean": "ë°•ì‚¬"}, "farmer": {"korean": "ë†ë¶€"},
            "girl": {"korean": "ì†Œë…€"}, "idol": {"korean": "ì•„ì´ëŒ"}, "merchant": {"korean": "ìƒì¸"},
            "ninja": {"korean": "ë‹Œì"}, "oldman": {"korean": "ë…¸ì¸"}, "princess": {"korean": "ê³µì£¼"},
            "rich": {"korean": "ë¶€ì"}, "wizard": {"korean": "ë§ˆë²•ì‚¬"}, "god": {"korean": "ì‹ "},
            "tiger": {"korean": "í˜¸ë‘ì´"}, "ghost": {"korean": "ìœ ë ¹"}, "devil": {"korean": "ë§ˆì™•"}
        }

        for name, details in character_details.items():
            image_path = os.path.join(CHARACTERS_DIR, f"{name}.png")
            txt_path = os.path.join(CHARACTERS_DIR, f"{name}.txt")
            prompt = ""
            if os.path.exists(txt_path):
                with open(txt_path, 'r', encoding='utf-8') as f:
                    prompt = f.read().strip()
            
            if os.path.exists(image_path) or name in ["god", "tiger", "ghost", "devil"]:
                entity = Entity(
                    name=name,
                    korean_name=details["korean"],
                    entity_type='ì¸ë¬¼',
                    image_path=image_path if os.path.exists(image_path) else None,
                    prompt=prompt
                )
                self.entities[name] = entity
                self.korean_to_english_map[details["korean"]] = name

        # 2. init_db.sqlì˜ í‚¤ì›Œë“œ ì •ë³´ ë¡œë“œ
        sql_entities = {
            'í˜¸ë‘ì´': 'tiger', 'ìœ ë ¹': 'ghost', 'ë†ë¶€': 'farmer', 'ìƒì¸': 'merchant', 'ì‹ ': 'god', 
            'ì™¸ê³„ì¸': 'alien', 'ë°•ì‚¬': 'doctor', 'ì•„ì´ëŒ': 'idol', 'ë§ˆë²•ì‚¬': 'wizard', 'ë§ˆì™•': 'devil',
            'ì†Œë…„': 'boy', 'ì†Œë…€': 'girl', 'ë¶€ì': 'rich', 'íƒì •': 'detective', 'ë…¸ì¸': 'oldman', 
            'ê°€ë‚œë±…ì´': 'beggar', 'ê³µì£¼': 'princess', 'ë‹Œì': 'ninja',
            'í•¸ë“œí°': 'phone', 'ë§ˆì°¨': 'carriage', 'ì¸í˜•': 'doll', 'ë¶€ì ': 'talisman', 'ì§€ë„': 'map',
            'ê°€ë©´': 'mask', 'ì¹¼': 'sword', 'í”¼ë¦¬': 'flute', 'ì§€íŒ¡ì´': 'staff', 'íƒœì–‘': 'sun',
            'ë‚ ê°œ': 'wings', 'ì˜ì': 'chair', 'ì‹œê³„': 'clock', 'ë„ì¥': 'stamp', 'ë³´ì„': 'gem',
            'UFO': 'ufo', 'ë«': 'trap', 'ì´': 'gun', 'íƒ€ì„ë¨¸ì‹ ': 'timemachine', 'ê°ì': 'potato',
            'ë°”ë‹¤': 'sea', 'ë‹¤ë¦¬': 'bridge', 'ë¬˜ì§€': 'cemetery', 'ì‹ë‹¹': 'restaurant', 'ë°•ë¬¼ê´€': 'museum',
            'ë¹„ë°€í†µë¡œ': 'secretpassage', 'ì‚¬ë§‰': 'desert', 'ì €íƒ': 'mansion', 'ì²œêµ­': 'heaven'
        }
        
        entity_types = {
            'í˜¸ë‘ì´': 'ì¸ë¬¼', 'ìœ ë ¹': 'ì¸ë¬¼', 'ë†ë¶€': 'ì¸ë¬¼', 'ìƒì¸': 'ì¸ë¬¼', 'ì‹ ': 'ì¸ë¬¼', 'ì™¸ê³„ì¸': 'ì¸ë¬¼',
            'ë°•ì‚¬': 'ì¸ë¬¼', 'ì•„ì´ëŒ': 'ì¸ë¬¼', 'ë§ˆë²•ì‚¬': 'ì¸ë¬¼', 'ë§ˆì™•': 'ì¸ë¬¼', 'ì†Œë…„': 'ì¸ë¬¼', 'ì†Œë…€': 'ì¸ë¬¼',
            'ë¶€ì': 'ì¸ë¬¼', 'íƒì •': 'ì¸ë¬¼', 'ë…¸ì¸': 'ì¸ë¬¼', 'ê°€ë‚œë±…ì´': 'ì¸ë¬¼', 'ê³µì£¼': 'ì¸ë¬¼', 'ë‹Œì': 'ì¸ë¬¼',
            'í•¸ë“œí°': 'ì‚¬ë¬¼', 'ë§ˆì°¨': 'ì‚¬ë¬¼', 'ì¸í˜•': 'ì‚¬ë¬¼', 'ë¶€ì ': 'ì‚¬ë¬¼', 'ì§€ë„': 'ì‚¬ë¬¼', 'ê°€ë©´': 'ì‚¬ë¬¼',
            'ì¹¼': 'ì‚¬ë¬¼', 'í”¼ë¦¬': 'ì‚¬ë¬¼', 'ì§€íŒ¡ì´': 'ì‚¬ë¬¼', 'íƒœì–‘': 'ì‚¬ë¬¼', 'ë‚ ê°œ': 'ì‚¬ë¬¼', 'ì˜ì': 'ì‚¬ë¬¼',
            'ì‹œê³„': 'ì‚¬ë¬¼', 'ë„ì¥': 'ì‚¬ë¬¼', 'ë³´ì„': 'ì‚¬ë¬¼', 'UFO': 'ì‚¬ë¬¼', 'ë«': 'ì‚¬ë¬¼', 'ì´': 'ì‚¬ë¬¼',
            'íƒ€ì„ë¨¸ì‹ ': 'ì‚¬ë¬¼', 'ê°ì': 'ì‚¬ë¬¼',
            'ë°”ë‹¤': 'ì¥ì†Œ', 'ë‹¤ë¦¬': 'ì¥ì†Œ', 'ë¬˜ì§€': 'ì¥ì†Œ', 'ì‹ë‹¹': 'ì¥ì†Œ', 'ë°•ë¬¼ê´€': 'ì¥ì†Œ',
            'ë¹„ë°€í†µë¡œ': 'ì¥ì†Œ', 'ì‚¬ë§‰': 'ì¥ì†Œ', 'ì €íƒ': 'ì¥ì†Œ', 'ì²œêµ­': 'ì¥ì†Œ'
        }

        for korean, english in sql_entities.items():
            if english not in self.entities:
                self.entities[english] = Entity(
                    name=english,
                    korean_name=korean,
                    entity_type=entity_types.get(korean, 'ì‚¬ë¬¼')
                )
            self.korean_to_english_map[korean] = english
            if korean == 'ì†Œë…„': self.korean_to_english_map['ì†Œë…€'] = 'girl'
            if korean == 'UFO': self.korean_to_english_map['ufo'] = 'ufo'

    def get_entity(self, name: str) -> Optional[Entity]:
        return self.entities.get(name)

    def detect_entities_in_text(self, text: str) -> List[str]:
        detected = []
        for korean, english in self.korean_to_english_map.items():
            if korean in text:
                detected.append(english)
        # ì˜ì–´ ì´ë¦„ìœ¼ë¡œë„ íƒì§€
        for english_name in self.entities.keys():
            if english_name in text.lower():
                detected.append(english_name)

        # 'ì†Œë…„'ê³¼ 'ì†Œë…€'ëŠ” 'boy'ì™€ 'girl'ë¡œ ê°ê° ì²˜ë¦¬
        if 'ì†Œë…„' in text and 'boy' not in detected: detected.append('boy')
        if 'ì†Œë…€' in text and 'girl' not in detected: detected.append('girl')

        return sorted(list(set(detected)), key=lambda x: text.find(self.get_entity(x).korean_name) if self.get_entity(x) else -1)

class GPTPromptGenerator:
    def __init__(self):
        if not OPENAI_API_KEY:
            raise ValueError("OPENAI_API_KEY environment variable is not set")
        
        self.client = OpenAI(api_key=OPENAI_API_KEY)
        
        # ê¸°ì¡´ AYL.pyì˜ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œì„ ê·¸ëŒ€ë¡œ í™œìš©
        self.story_prompt = """
You are an AI assistant specialized in summarizing stories in English and Korean stories currently entered. 
Your mission is to fully grasp the context of the summarized story and the Korean story currently entered, and then update the summarized English story. 
1. Mandatory Format: You must print only the summary story. 
2. Summarization of Inputs: - Continuously build a coherent summary of the story based on all user inputs up to the current point. 
   - Ensure that each subject appears only once in the [Subject] component, eliminating any duplicates. 
3. Missing or Partial Information: - If the user's input lacks certain components (e.g., no explicit Time), use context from the summarized story to maintain a natural, cohesive narrative. 
4. Strict Limitations: - Do not introduce new story elements beyond what the user provides. 
   - Do not modify or extend the user's narrative beyond summarization. 
   - Use only the content explicitly stated by the user, plus any relevant context from the summarized story to fill in missing details. 
# Important: - Add new information without ever deleting existing information. 
- Type of Input: Summarized story, current user input. 
- Output format: a summary of the summarized story and the current user's input.
"""
        
        self.description_prompt = """
You are a master storyteller AI. Your task is to interpret a new line in a story and create a vivid, context-aware 'Description' in English for an image generation AI. You must ensure narrative and character continuity.

**Core Inputs:**
- **Previous Description:** The description of the last scene.
- **Story Summary:** A summary of the entire story so far.
- **Current User Input:** The new sentence to add to the story.

**Reasoning Steps & Rules:**

1.  **Identify the Actor:**
    - **Rule:** If the `Current User Input` lacks a clear subject (e.g., "He went to the restaurant" or "Went to the restaurant"), you MUST infer the actor from the `Previous Description` or `Story Summary`. The most recently active character is the default actor.
    - **Action:** Explicitly state who is performing the action. Example: "The farmer, from the previous scene, goes to the restaurant."

2.  **Maintain Scene Cohesion:**
    - **Rule:** Assume the scene continues in the same location unless the `Current User Input` explicitly states a change of location.
    - **Action:** If the location is the same, integrate the new action into the existing environment from the `Previous Description`. If the location changes, describe the new environment.

3.  **Update Subject States, Don't Replace:**
    - **Rule:** For each subject (character, object), compare their state in the `Previous Description` with the `Current User Input` and describe the *change*.
    - **Sub-points for Each Subject:**
        *   **Physical/External Features:** Maintain consistency. Do not change unless explicitly stated.
        *   **Emotional Expressions & Actions/Poses:** Describe the transition. Instead of "The farmer is sad," write "The farmer, who was previously happy, now looks sad."
        *   **Relative Positioning:** Update the positions of all subjects relative to each other and the environment.

4.  **Synthesize the Final Description:**
    - **Format:** Structure your output into sections: `Main Subjects` (with sub-points for each), `Environment`, and `Mood & Narrative`.
    - **Clarity:** The description must be a clear and unambiguous instruction for the image generator.
    - **Conciseness:** Remove any redundant information from the `Previous Description` that is no longer relevant. The goal is a snapshot of the *current* moment, informed by the past.

**Example Scenario:**
-   **Previous Description:** "A happy farmer is standing in his field."
-   **Story Summary:** "A farmer was happy in his field."
-   **Current User Input:** "He felt hungry and went to the restaurant."

**Your Output should be structured like this:**

**Main Subjects:**
-   **Farmer:**
    -   Physical/External Features: (Consistent traits from before)
    -   Emotional Expressions: His expression changes from happy to hungry and determined.
    -   Actions/Poses: He is now walking towards or entering a restaurant, leaving his field behind.
**Environment:**
-   The scene transitions from a field to a restaurant. Describe the look of the restaurant.
**Mood & Narrative:**
-   The mood shifts from peaceful to one of purpose and need.
"""
        
        self.image_prompt = """
You are a cinematic artist AI. You will receive a 'Description' that details a scene, including subjects, environment, and mood. Your job is to convert this description into a single, ultra-detailed paragraph for an image generation model.

**Crucial Rule:** All subjects mentioned in the 'Main Subjects' section of the Description MUST appear together in the final image, interacting as described.

**Instructions:**

1.  **Synthesize, Don't List:** Read the entire `Description` to understand the complete context. Do not just translate points one-by-one.
2.  **Combine All Elements:** Weave together all subjects, their actions, their emotions, and their environment into one cohesive and vivid scene. If the description says "A farmer is in a restaurant," both the farmer and the restaurant must be clearly depicted in the same frame.
3.  **Dynamic Scene:** Use strong, cinematic language. Start the paragraph with "ultra-detailed cinematic scene,". Describe the lighting, camera angle, textures, and atmosphere to create a rich and immersive image.
4.  **Respect the Details:** Strictly adhere to the physical features, emotional states, actions, and relative positioning provided in the `Description`.

**Example:**
- **Input Description:**
    -   Main Subjects:
        -   Farmer: Sad, holding a golden staff.
        -   Restaurant: Dimly lit.
- **Your Output:** "ultra-detailed cinematic scene, inside a dimly lit restaurant, a sad farmer is sitting at a wooden table, holding a glowing golden staff in his hands. The soft light from the staff illuminates his melancholic face."
"""
    
    def generate_story_summary(self, previous_summary: str, user_input: str) -> str:
        """ìŠ¤í† ë¦¬ ìš”ì•½ ìƒì„±"""
        combined_input = f"Story_summary: {previous_summary}\nUser_Input: {user_input}"
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-5-nano",
                messages=[
                    {"role": "system", "content": self.story_prompt},
                    {"role": "user", "content": combined_input}
                ],
                max_tokens=4096,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"Error in story summary generation: {e}")
            return previous_summary
    
    def generate_description(self, previous_description: str, story_summary: str, user_input: str) -> str:
        """ì¥ë©´ ì„¤ëª… ìƒì„±"""
        combined_input = f"Story summary: {story_summary}\nDescription: {previous_description}\nCurrent story: {user_input}"
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-5-nano",
                messages=[
                    {"role": "system", "content": self.description_prompt},
                    {"role": "user", "content": combined_input}
                ],
                max_tokens=4096,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"Error in description generation: {e}")
            return previous_description
    
    def generate_image_prompt(self, description: str, user_input: str) -> str:
        """ì´ë¯¸ì§€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        combined_input = f"Description: {description}\nCurrent story: {user_input}"
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-5-nano",
                messages=[
                    {"role": "system", "content": self.image_prompt},
                    {"role": "user", "content": combined_input}
                ],
                max_tokens=4096,
                temperature=0.7
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"Error in image prompt generation: {e}")
            return description

class GeminiImageGenerator:
    def __init__(self):
        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY environment variable is not set")
        
        genai.configure(api_key=GEMINI_API_KEY)
        self.model = genai.GenerativeModel("gemini-2.5-flash-image-preview")
    
    def generate_text_to_image(self, prompt: str, art_style: str = "") -> bytes:
        """í…ìŠ¤íŠ¸ì—ì„œ ì´ë¯¸ì§€ ìƒì„± (ìºë¦­í„° ì—†ëŠ” ê²½ìš°)"""
        # 9:16 ë¹„ìœ¨ ëª…ì‹œ (ì„¸ë¡œí˜•, 720x1280 í•´ìƒë„)
        full_prompt = f"{prompt} {art_style} portrait orientation, 9:16 aspect ratio, vertical format, 720x1280 resolution".strip()
        
        try:
            response = self.model.generate_content([
                f"Generate an image: {full_prompt}"
            ])
            
            # ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
            if response.candidates and response.candidates[0].content.parts:
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'inline_data'):
                        return base64.b64decode(part.inline_data.data)
            
            raise Exception("No image data in response")
            
        except Exception as e:
            print(f"Error in text-to-image generation: {e}")
            raise
    
    def generate_image_to_image(self, character_images: List[Image.Image], prompt: str, character_prompts: List[str], art_style: str = "") -> bytes:
        """ì´ë¯¸ì§€ì—ì„œ ì´ë¯¸ì§€ ìƒì„± (ìºë¦­í„° ìˆëŠ” ê²½ìš°)"""
        try:
            # ìºë¦­í„° í”„ë¡¬í”„íŠ¸ë“¤ì„ ê²°í•©
            combined_character_prompt = " ".join(character_prompts)
            
            # ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (9:16 ë¹„ìœ¨ ëª…ì‹œ)
            full_prompt = f"Generate an image based on these reference images. {combined_character_prompt} {prompt} {art_style} portrait orientation, 9:16 aspect ratio, vertical format, 720x1280 resolution".strip()
            
            # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì „ë‹¬
            content = [full_prompt] + character_images
            
            response = self.model.generate_content(content)
            
            # ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ
            if response.candidates and response.candidates[0].content.parts:
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'inline_data'):
                        return base64.b64decode(part.inline_data.data)
            
            raise Exception("No image data in response")
            
        except Exception as e:
            print(f"Error in image-to-image generation: {e}")
            raise

class APIImageGenerationSystem:
    def __init__(self):
        self.entity_manager = EntityManager()
        self.gpt_generator = GPTPromptGenerator()
        self.gemini_generator = GeminiImageGenerator()
        
        # ê·¸ë¦¼ì²´ë³„ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ (ê¸°ì¡´ LoRA ëŒ€ì²´)
        self.art_styles = {
            0: "anime style, vibrant colors, detailed illustration",
            1: "cute 3d cartoon style, soft colors, rounded features",
            2: "comic strip style, bold outlines, dramatic expressions",
            3: "claymation style, 3D rendered, soft clay texture",
            4: "crayon drawing style, childlike, soft pastels",
            5: "pixel art style, retro gaming aesthetic, sharp pixels",
            6: "minimalist illustration, clean lines, simple colors",
            7: "watercolor painting style, soft blending, artistic",
            8: "storybook illustration, whimsical, detailed"
        }
    
    async def generate_image(self, 
                           user_input: str, 
                           game_mode: int, 
                           session_data: Dict) -> Tuple[bytes, Dict]:
        """
        ë©”ì¸ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
            game_mode: ê²Œì„ ëª¨ë“œ (0-8, ê·¸ë¦¼ì²´ ê²°ì •)
            session_data: ì„¸ì…˜ ë°ì´í„° (prev_prompt, summary, description í¬í•¨)
        
        Returns:
            Tuple[bytes, Dict]: (ì´ë¯¸ì§€ ë°”ì´íŠ¸ ë°ì´í„°, ì—…ë°ì´íŠ¸ëœ ì„¸ì…˜ ë°ì´í„°)
        """
        
        # 1. GPTë¥¼ í†µí•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        print("ğŸ”¹ [GPT] ìŠ¤í† ë¦¬ ìš”ì•½ ìƒì„± ì¤‘...")
        story_summary = self.gpt_generator.generate_story_summary(
            session_data.get("summary", ""), 
            user_input
        )
        
        print("ğŸ”¹ [GPT] ì¥ë©´ ì„¤ëª… ìƒì„± ì¤‘...")
        description = self.gpt_generator.generate_description(
            session_data.get("description", ""),
            story_summary,
            user_input
        )
        
        print("ğŸ”¹ [GPT] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        image_prompt = self.gpt_generator.generate_image_prompt(description, user_input)
        
        # 2. ê°œì²´ íƒì§€ ë° ë ˆí¼ëŸ°ìŠ¤ ê´€ë¦¬
        detected_entities = self.entity_manager.detect_entities_in_text(user_input)
        print(f"ğŸ”¹ [ê°œì²´ íƒì§€] ë°œê²¬ëœ ê°œì²´: {detected_entities}")

        entity_references = session_data.get('entity_references', {})
        newly_referenced_entities = {} # ì´ë²ˆ í„´ì— ë ˆí¼ëŸ°ìŠ¤ê°€ ìƒì„±/ì—…ë°ì´íŠ¸ëœ ê°œì²´
        
        # 3. ê·¸ë¦¼ì²´ ìŠ¤íƒ€ì¼ ê°€ì ¸ì˜¤ê¸°
        art_style = self.art_styles.get(game_mode, "")

        # 4. ì²« ë“±ì¥ ì‚¬ë¬¼/ì¥ì†Œì— ëŒ€í•œ ê°œë³„ ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ìƒì„±
        for entity_name in detected_entities:
            if entity_name not in entity_references:
                entity = self.entity_manager.get_entity(entity_name)
                # ìºë¦­í„°ê°€ ì•„ë‹ˆê±°ë‚˜, ìºë¦­í„°ì§€ë§Œ ê¸°ë³¸ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš°
                if entity and (entity.entity_type != 'ì¸ë¬¼' or not entity.image_path):
                    print(f"   - ì²« ë“±ì¥ (ì´ë¯¸ì§€ ì—†ìŒ): '{entity.korean_name}'. ê°œë³„ ë ˆí¼ëŸ°ìŠ¤ ìƒì„± ì¤‘...")
                    temp_prompt = f"A single, clear, centered image of a {entity.name} in a {art_style}, on a plain white background."
                    try:
                        ref_img_bytes = self.gemini_generator.generate_text_to_image(temp_prompt, art_style)
                        entity_references[entity_name] = ref_img_bytes
                        newly_referenced_entities[entity_name] = ref_img_bytes
                        print(f"   - '{entity.korean_name}' ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ.")
                    except Exception as e:
                        print(f"   - '{entity.korean_name}' ë ˆí¼ëŸ°ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")

        # 5. ìµœì¢… ì´ë¯¸ì§€ ìƒì„±
        images_for_gemini = []
        entity_prompts = []
        
        if detected_entities:
            print("ğŸ”¹ [Gemini] ìµœì¢… ì´ë¯¸ì§€ ìƒì„± (Image-to-Image ëª¨ë“œ)...")
            for entity_name in detected_entities:
                entity = self.entity_manager.get_entity(entity_name)
                if not entity: continue

                if entity.prompt: entity_prompts.append(entity.prompt)

                if entity_name in entity_references:
                    # ì¬ë“±ì¥ ë˜ëŠ” ì´ë²ˆì— ìƒì„±ëœ ë ˆí¼ëŸ°ìŠ¤ ì‚¬ìš©
                    print(f"   - ë ˆí¼ëŸ°ìŠ¤ ì‚¬ìš©: '{entity.korean_name}'")
                    images_for_gemini.append(Image.open(io.BytesIO(entity_references[entity_name])))
                elif entity.image_path: # ìºë¦­í„° ì²« ë“±ì¥
                    print(f"   - ê¸°ë³¸ ë ˆí¼ëŸ°ìŠ¤ ì‚¬ìš©: '{entity.korean_name}' (ìºë¦­í„° ì²« ë“±ì¥)")
                    with open(entity.image_path, "rb") as f: images_for_gemini.append(Image.open(f))
            
            image_bytes = self.gemini_generator.generate_image_to_image(images_for_gemini, image_prompt, entity_prompts, art_style)
        else:
            print("ğŸ”¹ [Gemini] Text-to-Image ëª¨ë“œë¡œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
            image_bytes = self.gemini_generator.generate_text_to_image(image_prompt, art_style)

        # 6. ì²« ë“±ì¥ ìºë¦­í„° ë ˆí¼ëŸ°ìŠ¤ ì—…ë°ì´íŠ¸
        for entity_name in detected_entities:
            if entity_name not in session_data.get('entity_references', {}) and entity_name not in newly_referenced_entities:
                entity = self.entity_manager.get_entity(entity_name)
                if entity and entity.entity_type == 'ì¸ë¬¼':
                    print(f"ğŸ”¹ [ë ˆí¼ëŸ°ìŠ¤ ì—…ë°ì´íŠ¸] ì²« ë“±ì¥ ìºë¦­í„° '{entity.korean_name}'ì˜ ë ˆí¼ëŸ°ìŠ¤ë¥¼ ìµœì¢… ì´ë¯¸ì§€ë¡œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.")
                    entity_references[entity_name] = image_bytes

        # 7. ì„¸ì…˜ ë°ì´í„° ì—…ë°ì´íŠ¸
        updated_session_data = {
            "prev_prompt": image_prompt,
            "summary": story_summary,
            "description": description,
            "entity_references": entity_references
        }
        
        print("âœ… [ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ]")
        return image_bytes, updated_session_data

# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
async def test_system():
    """ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    system = APIImageGenerationSystem()
    
    # í…ŒìŠ¤íŠ¸ ì„¸ì…˜ ë°ì´í„°
    session_data = {
        "prev_prompt": "",
        "summary": "",
        "description": ""
    }
    
    # í…ŒìŠ¤íŠ¸ 1: ìºë¦­í„° ì—†ëŠ” ê²½ìš°
    print("=== í…ŒìŠ¤íŠ¸ 1: ìºë¦­í„° ì—†ëŠ” ê²½ìš° ===")
    try:
        image_bytes, updated_data = await system.generate_image(
            "ì•„ë¦„ë‹¤ìš´ ìˆ²ì†ì— í–‡ë¹›ì´ ë¹„ì¹˜ê³  ìˆë‹¤", 
            0,  # ì• ë‹ˆë©”ì´ì…˜ ìŠ¤íƒ€ì¼
            session_data
        )
        print(f"ìƒì„±ëœ ì´ë¯¸ì§€ í¬ê¸°: {len(image_bytes)} bytes")
        session_data = updated_data
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ 1 ì‹¤íŒ¨: {e}")
    
    # í…ŒìŠ¤íŠ¸ 2: ìºë¦­í„° ìˆëŠ” ê²½ìš°
    print("=== í…ŒìŠ¤íŠ¸ 2: ìºë¦­í„° ìˆëŠ” ê²½ìš° ===")
    try:
        image_bytes, updated_data = await system.generate_image(
            "ë‹Œìê°€ ìˆ²ì†ì—ì„œ ìˆ˜í–‰ì„ í•˜ê³  ìˆë‹¤", 
            1,  # 3D ì¹´íˆ° ìŠ¤íƒ€ì¼
            session_data
        )
        print(f"ìƒì„±ëœ ì´ë¯¸ì§€ í¬ê¸°: {len(image_bytes)} bytes")
        session_data = updated_data
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ 2 ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    asyncio.run(test_system())
